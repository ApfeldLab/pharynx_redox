<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Demonstration of Profiled Estimation of Differential Equations</title>
      <meta name="generator" content="MATLAB 7.1">
      <meta name="date" content="2006-08-11">
      <meta name="m-file" content="FhNEx"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows.  On Gecko-based browsers, the shrink-to-fit doesn't work. */ 
p,h1,h2,div.content div {
  /* for MATLAB's browser */
  width: 600px;
  /* for Mozilla, but the "width" tag overrides it anyway */
  max-width: 600px;
  /* for IE */
  width:expression(document.body.clientWidth > 620 ? "600px": "auto" );
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Demonstration of Profiled Estimation of Differential Equations</h1>
         <introduction></introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">The FitzHugh-Nagumo Equations</a></li>
               <li><a href="#2">RHS Functions</a></li>
               <li><a href="#3">Various Parameters</a></li>
               <li><a href="#4">Observation times</a></li>
               <li><a href="#5">Calculate trajectories</a></li>
               <li><a href="#6">Set up observations</a></li>
               <li><a href="#7">Fitting parameters</a></li>
               <li><a href="#8">Profiling optimisation control</a></li>
               <li><a href="#9">Setting up Functional Data Objects</a></li>
               <li><a href="#10">Smooth the data</a></li>
               <li><a href="#11">Re-smoothing with model-based penalty</a></li>
               <li><a href="#12">Perform the Profiled Estimation</a></li>
               <li><a href="#13">Comparison with Smooth Using True Parameters</a></li>
               <li><a href="#14">Calculate Sample Information and Variance-Covariance Matrices</a></li>
            </ul>
         </div>
         <h2>The FitzHugh-Nagumo Equations<a name="1"></a></h2>
         <p>This page provides a detailed description of the MATLAB calculations necessary to run the profiling estimation code for differential
            equations.
         </p>
         <p>For further technical detail, please refer to the Profile_Users_Manual; available as a .pdf file in the code directory.</p>
         <p>The FitzHugh-Nagumo equations, as used in this example are given by</p>
         <p><img vspace="5" hspace="5" src="FhNEx_eq51078.png"> </p>
         <p><img vspace="5" hspace="5" src="FhNEx_eq53840.png"> </p>
         <p>We need to define define functions that will calculate this function and its derivatives.</p><pre class="codeinput"><span class="comment">% First, in order to set up Monte Carlo data, we need a function to put</span>
<span class="comment">% into the ode solver.</span>

odefn    = @fhnfunode;      <span class="comment">% Function for ODE solver (exact)</span>
</pre><h2>RHS Functions<a name="2"></a></h2>
         <p>Next, we require functions to evaluate the FitzHugh-Nagumo equations and their derivatives. These should accept the following
            as arguments:
         </p>
         <div>
            <ul>
               <li>a set of time points at which the functions are to be evaluate</li>
               <li>a cell array of functional data objects representing the current   estimated trajectory of the system</li>
               <li>a vector of parameters that will be estimated</li>
            </ul>
         </div>
         <p>Each function should return a cell array of values each element of which should contain a vector of values giving the derivative
            of a function in the system at the time points <tt>t</tt>.
         </p>
         <p>The array dimensions should always be ordered as: components of the system, derivatives with respect to components of the
            system, derivatives with respect to parameters.
         </p>
         <p>These functions should all be collated into a single struct, which will be labelled <tt>fn</tt> with the fields given below.
         </p>
         <p>The following functions are all given in the FhN subdirectory of the profiling code.</p><pre class="codeinput"><span class="comment">% First we need a function to calculate the functionl directly.</span>

fn.fn       = @fhnfun;       <span class="comment">% RHS function</span>

<span class="comment">% Now derivatives of the function with respect to system components and</span>
<span class="comment">% parameters</span>

fn.dfdx     = @fhndfdx;      <span class="comment">% Derivative wrt inputs (Jacobian)</span>
fn.dfdp     = @fhndfdp;      <span class="comment">% Derviative wrt parameters</span>

<span class="comment">% Now we need functions to compute all three sets of second derivatives:</span>

fn.d2fdx2   = @fhnd2fdx2;    <span class="comment">% Hessian wrt inputs</span>
fn.d2fdxdp  = @fhnd2fdxdp;   <span class="comment">% Hessian wrt inputs and parameters</span>
fn.d2fdp2   = @fhnd2fdp2;    <span class="comment">% Hessian wrt parameters.</span>

<span class="comment">% Finally, if we want to have variance estimates, various third derivatives</span>
<span class="comment">% are needed:</span>

fn.d3fdx3   = @fhnd3fdx3;    <span class="comment">% Third derivative wrt inputs.</span>
fn.d3fdx2dp = @fhnd3fdx2dp;  <span class="comment">% Third derivative wrt intputs, inputs and pars.</span>
fn.d3fdxdp2 = @fhnd3fdxdp2;  <span class="comment">% Third derivative wrt inputs, pars and pars.</span>
                             <span class="comment">% dimensions = time, component, input,</span>
                             <span class="comment">% parameters</span>
</pre><h2>Various Parameters<a name="3"></a></h2><pre class="codeinput"><span class="comment">% In order to specify a solution to a set of differential equations, we</span>
<span class="comment">% need to know initial conditions:</span>

y0 = [-1,1];

<span class="comment">% and parameters</span>

pars = [0.2; 0.2; 3];
disp([<span class="string">'Parameter values: '</span>,num2str(pars')])

<span class="comment">% We also need to specify the variance of observational noise:</span>

sigma = 1;

<span class="comment">% And we will choose a starting guess at the parameters by using a Guassian</span>
<span class="comment">% random jitter from the true parameter values with standard error:</span>

jitter = 0.2;

<span class="comment">% we then need to produce jittered parameters:</span>

startpars = pars + jitter*randn(length(pars),1);
disp([<span class="string">'Initial parameter values: '</span>,num2str(startpars')])
</pre><pre class="codeoutput">Parameter values: 0.2         0.2           3
Initial parameter values: 0.11349    -0.13312      3.0251
</pre><h2>Observation times<a name="4"></a></h2><pre class="codeinput"><span class="comment">% Now we need to specify the times at which we observe the system.</span>

tspan = 0:0.05:20;

<span class="comment">% We ultimately require these times to be given in a cell array, each cell</span>
<span class="comment">% specifying the observation times for one component of the system (empty</span>
<span class="comment">% cells signify unobserved components). The follow specifies with of the</span>
<span class="comment">% times in 'Tcell' will be observed for each component.</span>

<span class="comment">% In this case, all components will be observed at each time, but some</span>
<span class="comment">% (possibly empty) subset can be used instead.</span>

obs_pts{1} = 1:length(tspan);
obs_pts{2} = 1:length(tspan);


<span class="comment">% Finally, we will want to be able to plot what a true solution looks like</span>
<span class="comment">% on a fairly fine grid. This specifies that grid.</span>

tfine = 0:0.05:20;
</pre><h2>Calculate trajectories<a name="5"></a></h2>
         <p>We use the MATLAB routine <tt>ode45</tt> to solve the differential equation.
         </p><pre class="codeinput"><span class="comment">% First we need to set up a convergence tolerance for the numerical</span>
<span class="comment">% solution:</span>

odeopts = odeset(<span class="string">'RelTol'</span>,1e-13);

<span class="comment">% Now we will solve the equations at the true parameters and initial</span>
<span class="comment">% conditions to get values at the observation times.</span>

[full_time,full_path] = ode45(odefn,tspan,y0,odeopts,pars);

<span class="comment">% We also solve the equations to get values at the plotting grid for a</span>
<span class="comment">% visual comparison:</span>

[plot_time,plot_path] = ode45(odefn,tfine,y0,odeopts,pars);
</pre><h2>Set up observations<a name="6"></a></h2>
         <p>Finally, we set up MATLAB objects for the observations. These will be the objects <tt>Tcell</tt> and <tt>Ycell</tt> which will be cell arrays containing the observation times and observation values respectively. Each element of the cell
            array corresponds to one component of the FitzHugh-Nagumo system.
         </p><pre class="codeinput"><span class="comment">% We start by defining cell arrays:</span>

Tcell = cell(1,size(full_path,2));
path_cell = Tcell;

<span class="comment">% We take the data from the solution of the differential equation and put</span>
<span class="comment">% it into the appropriate component.</span>

<span class="keyword">for</span> i = 1:length(obs_pts)
    Tcell{i} = full_time(obs_pts{i});
    path_cell{i} = full_path(obs_pts{i},i);
<span class="keyword">end</span>

<span class="comment">% Finally, we add random observational noise to the 'path' variable.</span>

Ycell = path_cell;
<span class="keyword">for</span> i = 1:length(path_cell)
    Ycell{i} = path_cell{i} + sigma*randn(size(path_cell{i}));
<span class="keyword">end</span>

<span class="comment">% To observe the raw data and the true path, we can plot</span>

figure(1)
<span class="keyword">for</span> i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(plot_time,plot_path(:,i),<span class="string">'r'</span>)
    hold <span class="string">on</span>
    plot(Tcell{i},Ycell{i},<span class="string">'b.'</span>)
    hold <span class="string">off</span>
    <span class="keyword">if</span> i==1
        ylabel(<span class="string">'\fontsize{13} V'</span>)
        title(<span class="string">'\fontsize{13} Raw data (.) and true path (-)'</span>)
    <span class="keyword">else</span>
        xlabel(<span class="string">'\fontsize{13} t'</span>)
        ylabel(<span class="string">'\fontsize{13} R'</span>)
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Finally, each observation requires a weight for its contribution to a sum</span>
<span class="comment">% of squared errors.  If this is left empty, the code will assume each</span>
<span class="comment">% weight is equal.  Otherwise, it should have the same format as 'Tcell'</span>
<span class="comment">% and 'Ycell'.</span>

wts = [];

<span class="comment">% Alternatively, we may decide to weight each component according to its</span>
<span class="comment">% scale. This can be done by associating a weight given by the inverse of</span>
<span class="comment">% the variance of the observations in that component.</span>

<span class="keyword">for</span> i = 1:length(Ycell)
    <span class="keyword">if</span> ~isempty(Ycell{i})
        wts(i) = 1./sqrt(var(path_cell{i}));
    <span class="keyword">else</span>
        wts(i) = 1;
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Technically, this variable should also be a cell array, giving one weight</span>
<span class="comment">% per observation. When it is given as a numeric array, it is assumed that</span>
<span class="comment">% the weight is constant accross observations in each component.</span>
</pre><img vspace="5" hspace="5" src="FhNEx_01.png"> <h2>Fitting parameters<a name="7"></a></h2>
         <p>Here we set up some control parameters for the profiling methodology that we will use.</p><pre class="codeinput"><span class="comment">% The first of these is the smoothing parameter, we will also multiply this</span>
<span class="comment">% by the weights for each component.</span>

lambda = 1e4;
lambda = lambda * wts;

<span class="comment">% We also set up a secondary smoothing parameter, this will be used to</span>
<span class="comment">% provide an initial smooth to the data without reference to the</span>
<span class="comment">% differential equation.</span>

lambda0 = 1;

<span class="comment">% Now, we need to define some meta-parameters of a B-spline basis. First of</span>
<span class="comment">% these is the number of knots:</span>

nknots = 401;

<span class="comment">% Then the order of B-spline that we will employ:</span>

norder = 3;

<span class="comment">% Finally, since we will need to evaluate a non-linear penaly, we need the</span>
<span class="comment">% number of quadrature points between knots that will be used to perform</span>
<span class="comment">% numerical integration:</span>

nquad = 5;
</pre><h2>Profiling optimisation control<a name="8"></a></h2>
         <p>Here, we set up some control parameters for performing non-linear optimization. All optimization is doen by a Gauss-Newton
            method. However, there are two distinct levels of optimization. These control values take the form of the options in the MATLAB
            nonlinear optimization toolbox.
         </p>
         <p>In all cases, the options should be set to use a Jacobian. I have also specified some tolerances and the 'Display' variable.</p><pre class="codeinput"><span class="comment">% Firstly, there is the outer-optimization of the structural parameters.</span>
<span class="comment">% We need to be less concerned about very fine convergence, but it is</span>
<span class="comment">% appropriate to display progress every iteration.</span>

lsopts_out = optimset(<span class="string">'DerivativeCheck'</span>,<span class="string">'off'</span>,<span class="string">'Jacobian'</span>,<span class="string">'on'</span>,<span class="keyword">...</span>
    <span class="string">'Display'</span>,<span class="string">'iter'</span>,<span class="string">'MaxIter'</span>,1000,<span class="string">'TolFun'</span>,1e-8,<span class="string">'TolX'</span>,1e-10);

<span class="comment">% Then, there is the inner optimization loop to perform a smooth with a</span>
<span class="comment">% non-linear penalty. Here it is important to have tight convergence</span>
<span class="comment">% tolerances, but displaying the progress of the optimization will make the</span>
<span class="comment">% output messy. The Gauss-Newton optimization can be speeded up using a</span>
<span class="comment">% set of sparse matrix multiplication routines which is specified by</span>
<span class="comment">% setting 'JacobMult' to '@SparseJMfun'.</span>

lsopts_in = optimset(<span class="string">'DerivativeCheck'</span>,<span class="string">'off'</span>,<span class="string">'Jacobian'</span>,<span class="string">'on'</span>,<span class="keyword">...</span>
    <span class="string">'Display'</span>,<span class="string">'off'</span>,<span class="string">'MaxIter'</span>,1000,<span class="string">'TolFun'</span>,1e-14,<span class="string">'TolX'</span>,1e-14,<span class="keyword">...</span>
    <span class="string">'JacobMult'</span>,@SparseJMfun);

<span class="comment">% Finally, sometimes we want to just do the smoothing. The following</span>
<span class="comment">% options are the same as for the inner optimization, but the 'Display'</span>
<span class="comment">% option is set to output a summary when the routine finishes.</span>

lsopts_other = optimset(<span class="string">'DerivativeCheck'</span>,<span class="string">'off'</span>,<span class="string">'Jacobian'</span>,<span class="string">'on'</span>,<span class="keyword">...</span>
    <span class="string">'Display'</span>,<span class="string">'off'</span>,<span class="string">'MaxIter'</span>,1000,<span class="string">'TolFun'</span>,1e-14,<span class="string">'TolX'</span>,1e-14,<span class="keyword">...</span>
    <span class="string">'JacobMult'</span>,@SparseJMfun);
</pre><h2>Setting up Functional Data Objects<a name="9"></a></h2><pre class="codeinput"><span class="comment">% Firstly, we need to produce a basis function for each component of the</span>
<span class="comment">% system. To begin with, they all need to have the same range specified:</span>

range = [min(full_time),max(full_time)];

<span class="comment">% Now we create a cell-array containing the knots for B-spline bases. In</span>
<span class="comment">% this case, each basis will contain 401 equally spaced knots. Note</span>
<span class="comment">% however, that we could have different bases.</span>

knots_cell = cell(1,size(Ycell,2));
knots_cell(:) = {linspace(range(1),range(2),401)};

<span class="comment">% The bases are also contained in a cell array:</span>

basis_cell = cell(1,length(Ycell));

<span class="comment">% At the same time, we will create a cell array of Lfd objects. This will</span>
<span class="comment">% be used to perform an initial smooth of the data:</span>

Lfd_cell = cell(1,length(Ycell));

<span class="comment">% We will also need to calculate the number of basis functions for each</span>
<span class="comment">% component of the system:</span>

nbasis = zeros(length(Ycell),1);

<span class="comment">% Finally, quadrature points will have to be common to all bases in the</span>
<span class="comment">% system. The following code creates 'bigknots', a large vector</span>
<span class="comment">% containing all the knots for all the bases, it also calculates the number</span>
<span class="comment">% of basis functions for each component:</span>

bigknots = knots_cell{1};
nbasis(1) = length(knots_cell{1}) + norder - 2;

<span class="keyword">for</span> i = 2:length(Ycell)
    bigknots = [bigknots knots_cell{i}];
    nbasis(i) = length(knots_cell{i}) + norder -2;
<span class="keyword">end</span>

<span class="comment">% We can now use 'bigknots' to create a set of quadrature points.</span>
<span class="comment">% 'quadvals' contains Simpson's Rule quadrature points and quadrature</span>
<span class="comment">% weights based on 'nquad' quadrature points between each successive</span>
<span class="comment">% knot value.</span>

quadvals = MakeQuadPoints(bigknots,nquad);

<span class="comment">% Now we can create the basis and Lfd objects to popluate 'basis_cell'</span>
<span class="comment">% and 'Lfd_cell'. In this case 'MakeBasis' simply creates a B-spline basis</span>
<span class="comment">% and attaches 'quadvals' as quadrature points. We have chosen 'Lfd_cell'</span>
<span class="comment">% to contain objects penalizing the first derivative of a smooth.</span>

<span class="keyword">for</span> i = 1:length(Ycell)
    basis_cell{i} = MakeBasis(range,nbasis(i),norder,<span class="keyword">...</span>
        knots_cell{i},quadvals,1);
    Lfd_cell{i} = fdPar(basis_cell{i},1,lambda0);
<span class="keyword">end</span>
</pre><h2>Smooth the data<a name="10"></a></h2><pre class="codeinput"><span class="comment">% As a first step, we create a smooth of the data without reference to the</span>
<span class="comment">% differential equation. 'smoothfd_cell' does this for each component</span>
<span class="comment">% individually using the penalty specified in 'Lfd_cell'.</span>

DEfd = smoothfd_cell(Ycell,Tcell,Lfd_cell);

<span class="comment">% We will use the coefficients estimated via this smooth as initial values</span>
<span class="comment">% for the non-linear smoothing problem when we use a model-based penalty.</span>
<span class="comment">% getcellcoefs takes a cell array of functional data objects and</span>
<span class="comment">% returns a vector concatenating all the coefficient vectors.</span>

coefs = getcellcoefs(DEfd);

<span class="comment">% plot the smooth</span>

figure(2)
devals = eval_fdcell(tfine,DEfd,0);
<span class="keyword">for</span> i = 1:length(Ycell)
    subplot(length(Ycell),1,i);
    plot(tfine,devals{i},<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,2);
    hold <span class="string">on</span>;
    plot(Tcell{i},Ycell{i},<span class="string">'b.'</span>);
    hold <span class="string">off</span>;
    <span class="keyword">if</span> i==1
        ylabel(<span class="string">'\fontsize{13} V'</span>)
        title(<span class="string">'\fontsize{13} Raw data (.) and smoothing path (-)'</span>)
    <span class="keyword">else</span>
        xlabel(<span class="string">'\fontsize{13} t'</span>)
        ylabel(<span class="string">'\fontsize{13} R'</span>)
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="FhNEx_02.png"> <h2>Re-smoothing with model-based penalty<a name="11"></a></h2>
         <p>Now we get into some of the grunt work of the method. First, we will smooth the data using the differential equation as a
            penalty, but with the jittered parameters.
         </p><pre class="codeinput"><span class="comment">% This is done by a call to the MATLAB optimizer 'lsqnonlin' which</span>
<span class="comment">% gives out the optimized coefficients of the basis.</span>

[newcoefs,resnorm2] = lsqnonlin(@SplineCoefErr,coefs,[],[],<span class="keyword">...</span>
    lsopts_other,basis_cell,Ycell,Tcell,wts,lambda,fn,[],startpars);

<span class="comment">% 'Make_fdcell' takes those coefficients and creates functional data</span>
<span class="comment">% objects using the entries in 'basis_cell'.</span>

tDEfd = Make_fdcell(newcoefs,basis_cell);

<span class="comment">% plot results along with exact solution</span>

figure(3)
devals = eval_fdcell(tfine,tDEfd,0);
<span class="keyword">for</span> i = 1:length(Ycell)
    subplot(length(Ycell),1,i);
    plot(tfine,devals{i},<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,2);
    hold <span class="string">on</span>;
    plot(Tcell{i},Ycell{i},<span class="string">'b.'</span>);
    plot(plot_time,plot_path(:,i),<span class="string">'g'</span>);
    hold <span class="string">off</span>
    <span class="keyword">if</span> i==1
        ylabel(<span class="string">'\fontsize{13} V'</span>)
        title([<span class="string">'\fontsize{13} Raw data (.), '</span>, <span class="keyword">...</span>
               <span class="string">'exact solution (r-) and true path (g-)'</span>])
    <span class="keyword">else</span>
        xlabel(<span class="string">'\fontsize{13} t'</span>)
        ylabel(<span class="string">'\fontsize{13} R'</span>)
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="FhNEx_03.png"> <h2>Perform the Profiled Estimation<a name="12"></a></h2>
         <p><tt>Profile_GausNewt</tt> runs the Guass-Newton iteration for the outer optimization in profiling. It outputs the new parameter estimates along with
            a cell-array of functional data objects that give the model-based smooth to the data
         </p><pre class="codeinput">[newpars,newDEfd_cell] = Profile_GausNewt(startpars,lsopts_out,DEfd,fn,<span class="keyword">...</span>
    lambda,Ycell,Tcell,wts,[],lsopts_in);

disp([<span class="string">'New parameter estimates: '</span>,num2str(newpars')]);

<span class="comment">% plot smooth with profile-estimated parameters</span>

figure(4)
devals = eval_fdcell(tfine,newDEfd_cell,0);
<span class="keyword">for</span> i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(tfine,devals{i},<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,2);
    hold <span class="string">on</span>;
    plot(Tcell{i},Ycell{i},<span class="string">'b.'</span>);
    plot(plot_time,plot_path(:,i),<span class="string">'g'</span>,<span class="string">'linewidth'</span>,2);
    hold <span class="string">off</span>
    <span class="keyword">if</span> i==1
        ylabel(<span class="string">'\fontsize{13} V'</span>)
        title([<span class="string">'\fontsize{13} Raw data (.), '</span>, <span class="keyword">...</span>
               <span class="string">'profiled solution (r-) and true path (g-)'</span>])
    <span class="keyword">else</span>
        xlabel(<span class="string">'\fontsize{13} t'</span>)
        ylabel(<span class="string">'\fontsize{13} R'</span>)
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput">
 Iteration       steps    Residual   Improvement   Grad-norm     parameters
     1           1         777.747      0.014356         15.9     0.17242     0.21718      3.1879
     2           1         769.981    0.00998494        0.246     0.18103     0.26702      3.0125
     3           1         769.857   0.000160212         0.64     0.17886     0.30433      2.9921
     4           1         769.854  3.98122e-006       0.0329     0.17797     0.30682      2.9888
     5           1         769.854  7.50687e-008       0.0112     0.17778     0.30752      2.9885
     6           1         769.854  1.49666e-009      0.00065     0.17776     0.30758      2.9885
New parameter estimates: 0.17776     0.30758      2.9885
</pre><img vspace="5" hspace="5" src="FhNEx_04.png"> <h2>Comparison with Smooth Using True Parameters<a name="13"></a></h2>
         <p>How different is the smooth resulting from the estimated parameter values as compared with the true parameter values? Here
            we smooth again, but using the true parameter values.
         </p><pre class="codeinput"><span class="comment">% We'll start off with the estimated coefficients.</span>

coefs = getcellcoefs(DEfd);

<span class="comment">% and make a call to 'lsqnonlin'.</span>

[truecoefs,resnorm4] = lsqnonlin(@SplineCoefErr,coefs,[],[],<span class="keyword">...</span>
    lsopts_other,basis_cell,Ycell,Tcell,wts,lambda,fn,[],pars);

<span class="comment">% then create the functional data objects and plot them</span>

trueDEfd_cell = Make_fdcell(truecoefs,basis_cell);

figure(5)
devals = eval_fdcell(tfine,trueDEfd_cell,0);
<span class="keyword">for</span> i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(tfine,devals{i},<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,2);
    hold <span class="string">on</span>;
    plot(plot_time,plot_path(:,i),<span class="string">'g'</span>);
    plot(Tcell{i},Ycell{i},<span class="string">'b.'</span>);
    hold <span class="string">off</span>;
    <span class="keyword">if</span> i==1
        ylabel(<span class="string">'\fontsize{13} V'</span>)
        title([<span class="string">'\fontsize{13} Raw data (.), '</span>, <span class="keyword">...</span>
               <span class="string">'true par. smooth (r-) and true path (g-)'</span>])
    <span class="keyword">else</span>
        xlabel(<span class="string">'\fontsize{13} t'</span>)
        ylabel(<span class="string">'\fontsize{13} R'</span>)
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Finally we will compare squared error performance. To do this, we will</span>
<span class="comment">% first of all need to evaluate the functional data objects at the</span>
<span class="comment">% observatio points. 'eval_fdcell' does this:</span>

newpreds = eval_fdcell(Tcell,newDEfd_cell,0);

<span class="comment">% then we can create the weighted squared error pointwise</span>

new_err = cell(length(newpreds));
<span class="keyword">for</span> i = 1:length(Ycell)
    new_err{i} = wts(i)*(newpreds{i} - Ycell{i}).^2;
<span class="keyword">end</span>

<span class="comment">% 'cell2mat' is a handy function that will turn a cell array of matrices,</span>
<span class="comment">% into a large matrix using the elements of the cells as blocks. We can</span>
<span class="comment">% then take the mean accross all values.</span>

new_err = mean(cell2mat(new_err));

<span class="comment">% Now we can do the same thing for the smooth using the true parameters</span>

truepreds = eval_fdcell(Tcell,trueDEfd_cell,0);
true_err = cell(length(truepreds));
<span class="keyword">for</span> i = 1:length(Ycell)
    true_err{i} = wts(i)*(truepreds{i} - Ycell{i}).^2;
<span class="keyword">end</span>

true_err = mean(cell2mat(true_err));

<span class="comment">% and print out a comparison of the squared errors</span>

disp([<span class="string">'Estimated sqrd error: '</span>,num2str(new_err)])
disp([<span class="string">'True sqrd error:      '</span>,num2str(true_err)]);
</pre><pre class="codeoutput">Estimated sqrd error: 0.95992
True sqrd error:      0.96126
</pre><img vspace="5" hspace="5" src="FhNEx_05.png"> <h2>Calculate Sample Information and Variance-Covariance Matrices<a name="14"></a></h2>
         <p>Finally, we want to get an idea of the variability of the parameter estimates.</p><pre class="codeinput"><span class="comment">% We will start with the Hessian of squared error with respect to the</span>
<span class="comment">% parameters:</span>

d2Jdp2 = make_d2jdp2(newDEfd_cell,fn,Ycell,Tcell,lambda,newpars,[],wts);

<span class="comment">% We then want the cross derivatives of squared error with respect to</span>
<span class="comment">% parameters and observations:</span>

d2JdpdY = make_d2jdpdy(newDEfd_cell,fn,Ycell,Tcell,lambda,newpars,[],wts);

<span class="comment">% This allows us to calculate the derivative of the parameters with respect</span>
<span class="comment">% to observations:</span>

dpdY = -d2Jdp2\d2JdpdY;

<span class="comment">% Now we need to estimate how variable those observations are:</span>

S = make_sigma(DEfd,Tcell,Ycell,0);

<span class="comment">% And this gives an approximate covariance matrix for the parameters:</span>

Cov = dpdY*S*dpdY';

<span class="comment">%  Standard errors</span>

StdDev = sqrt(diag(Cov));

<span class="comment">%  Correlations</span>

Corr = Cov./(StdDev*StdDev');

<span class="comment">%  Display these results</span>

disp(<span class="string">'Approximate covariance matrix for parameters:'</span>)
disp(num2str(Cov))

disp(<span class="string">'Approximate standard errors of parameters:'</span>)
disp(num2str(StdDev'))

disp(<span class="string">'Approximate correlation matrix for parameters:'</span>)
disp(num2str(Corr))
</pre><pre class="codeoutput">Approximate covariance matrix for parameters:
0.00070892  -0.0013413  0.00054955
-0.0013413    0.013703  -0.0063636
0.00054955  -0.0063636   0.0043962
Approximate standard errors of parameters:
0.026626     0.11706    0.066304
Approximate correlation matrix for parameters:
       1    -0.43036     0.31129
-0.43036           1    -0.81987
 0.31129    -0.81987           1
</pre><p class="footer"><br>
            Published with MATLAB&reg; 7.1<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Demonstration of Profiled Estimation of Differential Equations
%% The FitzHugh-Nagumo Equations
%
% This page provides a detailed description of the MATLAB calculations
% necessary to run the profiling estimation code for differential
% equations. 
%
% For further technical detail, please refer to the Profile_Users_Manual;
% available as a .pdf file in the code directory. 
% 
% The FitzHugh-Nagumo equations, as used in this example are given by
% 
% $$\dot{x} = c \left(x - \frac{x^3}{3} + y \right)$$
%
% $$\dot{y} = -\frac{1}{c} \left( x - a + by \right)$$
%
% We need to define define functions that will calculate this function and
% its derivatives.

% First, in order to set up Monte Carlo data, we need a function to put
% into the ode solver. 

odefn    = @fhnfunode;      % Function for ODE solver (exact)

%% RHS Functions
%
% Next, we require functions to evaluate the FitzHugh-Nagumo equations and
% their derivatives. These should accept the following as arguments:
% 
% * a set of time points at which the functions are to be evaluate
% * a cell array of functional data objects representing the current
%   estimated trajectory of the system
% * a vector of parameters that will be estimated
%
% Each function should return a cell array of values each element of which
% should contain a vector of values giving the derivative of a function in
% the system at the time points |t|. 
%
% The array dimensions should always be ordered as: components of the
% system, derivatives with respect to components of the system, derivatives
% with respect to parameters. 
%
% These functions should all be collated into a single struct, which will
% be labelled |fn| with the fields given below. 
%
% The following functions are all given in the FhN subdirectory of the
% profiling code. 

% First we need a function to calculate the functionl directly. 

fn.fn       = @fhnfun;       % RHS function

% Now derivatives of the function with respect to system components and
% parameters 

fn.dfdx     = @fhndfdx;      % Derivative wrt inputs (Jacobian)
fn.dfdp     = @fhndfdp;      % Derviative wrt parameters

% Now we need functions to compute all three sets of second derivatives:

fn.d2fdx2   = @fhnd2fdx2;    % Hessian wrt inputs
fn.d2fdxdp  = @fhnd2fdxdp;   % Hessian wrt inputs and parameters
fn.d2fdp2   = @fhnd2fdp2;    % Hessian wrt parameters.    

% Finally, if we want to have variance estimates, various third derivatives
% are needed:

fn.d3fdx3   = @fhnd3fdx3;    % Third derivative wrt inputs.
fn.d3fdx2dp = @fhnd3fdx2dp;  % Third derivative wrt intputs, inputs and pars.
fn.d3fdxdp2 = @fhnd3fdxdp2;  % Third derivative wrt inputs, pars and pars. 
                             % dimensions = time, component, input,
                             % parameters
                         
                          
%% Various Parameters

% In order to specify a solution to a set of differential equations, we
% need to know initial conditions:

y0 = [-1,1];                      

% and parameters

pars = [0.2; 0.2; 3];          
disp(['Parameter values: ',num2str(pars')])

% We also need to specify the variance of observational noise:

sigma = 1;

% And we will choose a starting guess at the parameters by using a Guassian
% random jitter from the true parameter values with standard error:

jitter = 0.2;                   

% we then need to produce jittered parameters:

startpars = pars + jitter*randn(length(pars),1);
disp(['Initial parameter values: ',num2str(startpars')])


%% Observation times

% Now we need to specify the times at which we observe the system.

tspan = 0:0.05:20;

% We ultimately require these times to be given in a cell array, each cell
% specifying the observation times for one component of the system (empty
% cells signify unobserved components). The follow specifies with of the
% times in 'Tcell' will be observed for each component. 

% In this case, all components will be observed at each time, but some
% (possibly empty) subset can be used instead. 

obs_pts{1} = 1:length(tspan);       
obs_pts{2} = 1:length(tspan);      


% Finally, we will want to be able to plot what a true solution looks like
% on a fairly fine grid. This specifies that grid. 

tfine = 0:0.05:20;     

%% Calculate trajectories
%
% We use the MATLAB routine |ode45| to solve the differential equation.

% First we need to set up a convergence tolerance for the numerical
% solution:

odeopts = odeset('RelTol',1e-13);

% Now we will solve the equations at the true parameters and initial
% conditions to get values at the observation times. 

[full_time,full_path] = ode45(odefn,tspan,y0,odeopts,pars);

% We also solve the equations to get values at the plotting grid for a
% visual comparison:

[plot_time,plot_path] = ode45(odefn,tfine,y0,odeopts,pars);

%% Set up observations
%
% Finally, we set up MATLAB objects for the observations. These will be the
% objects |Tcell| and |Ycell| which will be cell arrays
% containing the observation times and observation values respectively.
% Each element of the cell array corresponds to one component of the
% FitzHugh-Nagumo system. 

% We start by defining cell arrays:

Tcell = cell(1,size(full_path,2));
path_cell = Tcell;

% We take the data from the solution of the differential equation and put
% it into the appropriate component. 

for i = 1:length(obs_pts)
    Tcell{i} = full_time(obs_pts{i});
    path_cell{i} = full_path(obs_pts{i},i);
end

% Finally, we add random observational noise to the 'path' variable. 

Ycell = path_cell;                
for i = 1:length(path_cell)
    Ycell{i} = path_cell{i} + sigma*randn(size(path_cell{i}));
end

% To observe the raw data and the true path, we can plot

figure(1)
for i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(plot_time,plot_path(:,i),'r')
    hold on
    plot(Tcell{i},Ycell{i},'b.')
    hold off
    if i==1
        ylabel('\fontsize{13} V')
        title('\fontsize{13} Raw data (.) and true path (-)')
    else
        xlabel('\fontsize{13} t')
        ylabel('\fontsize{13} R')
    end
end

% Finally, each observation requires a weight for its contribution to a sum 
% of squared errors.  If this is left empty, the code will assume each
% weight is equal.  Otherwise, it should have the same format as 'Tcell'
% and 'Ycell'.  

wts = [];  

% Alternatively, we may decide to weight each component according to its
% scale. This can be done by associating a weight given by the inverse of
% the variance of the observations in that component. 
                 
for i = 1:length(Ycell)
    if ~isempty(Ycell{i})
        wts(i) = 1./sqrt(var(path_cell{i}));
    else
        wts(i) = 1;
    end
end

% Technically, this variable should also be a cell array, giving one weight
% per observation. When it is given as a numeric array, it is assumed that
% the weight is constant accross observations in each component. 

%% Fitting parameters
%
% Here we set up some control parameters for the profiling methodology that
% we will use. 

% The first of these is the smoothing parameter, we will also multiply this
% by the weights for each component. 

lambda = 1e4;      
lambda = lambda * wts;

% We also set up a secondary smoothing parameter, this will be used to
% provide an initial smooth to the data without reference to the
% differential equation. 

lambda0 = 1;        

% Now, we need to define some meta-parameters of a B-spline basis. First of
% these is the number of knots:

nknots = 401;    

% Then the order of B-spline that we will employ:

norder = 3;

% Finally, since we will need to evaluate a non-linear penaly, we need the
% number of quadrature points between knots that will be used to perform
% numerical integration:

nquad = 5;     

%% Profiling optimisation control
%
% Here, we set up some control parameters for performing non-linear
% optimization. All optimization is doen by a Gauss-Newton method. However,
% there are two distinct levels of optimization. These control values take
% the form of the options in the MATLAB nonlinear optimization toolbox. 
%
% In all cases, the options should be set to use a Jacobian. I have also
% specified some tolerances and the 'Display' variable. 

% Firstly, there is the outer-optimization of the structural parameters.
% We need to be less concerned about very fine convergence, but it is
% appropriate to display progress every iteration.  

lsopts_out = optimset('DerivativeCheck','off','Jacobian','on',...
    'Display','iter','MaxIter',1000,'TolFun',1e-8,'TolX',1e-10);

% Then, there is the inner optimization loop to perform a smooth with a
% non-linear penalty. Here it is important to have tight convergence
% tolerances, but displaying the progress of the optimization will make the
% output messy. The Gauss-Newton optimization can be speeded up using a
% set of sparse matrix multiplication routines which is specified by
% setting 'JacobMult' to '@SparseJMfun'. 

lsopts_in = optimset('DerivativeCheck','off','Jacobian','on',...
    'Display','off','MaxIter',1000,'TolFun',1e-14,'TolX',1e-14,...
    'JacobMult',@SparseJMfun);

% Finally, sometimes we want to just do the smoothing. The following
% options are the same as for the inner optimization, but the 'Display'
% option is set to output a summary when the routine finishes.  

lsopts_other = optimset('DerivativeCheck','off','Jacobian','on',...
    'Display','off','MaxIter',1000,'TolFun',1e-14,'TolX',1e-14,...
    'JacobMult',@SparseJMfun);


%% Setting up Functional Data Objects

% Firstly, we need to produce a basis function for each component of the
% system. To begin with, they all need to have the same range specified:

range = [min(full_time),max(full_time)];

% Now we create a cell-array containing the knots for B-spline bases. In
% this case, each basis will contain 401 equally spaced knots. Note
% however, that we could have different bases. 

knots_cell = cell(1,size(Ycell,2));
knots_cell(:) = {linspace(range(1),range(2),401)};

% The bases are also contained in a cell array:

basis_cell = cell(1,length(Ycell)); 

% At the same time, we will create a cell array of Lfd objects. This will
% be used to perform an initial smooth of the data:

Lfd_cell = cell(1,length(Ycell));

% We will also need to calculate the number of basis functions for each
% component of the system:

nbasis = zeros(length(Ycell),1);

% Finally, quadrature points will have to be common to all bases in the
% system. The following code creates 'bigknots', a large vector
% containing all the knots for all the bases, it also calculates the number
% of basis functions for each component:  

bigknots = knots_cell{1};               
nbasis(1) = length(knots_cell{1}) + norder - 2;          

for i = 2:length(Ycell)
    bigknots = [bigknots knots_cell{i}];
    nbasis(i) = length(knots_cell{i}) + norder -2;
end

% We can now use 'bigknots' to create a set of quadrature points.
% 'quadvals' contains Simpson's Rule quadrature points and quadrature
% weights based on 'nquad' quadrature points between each successive
% knot value. 

quadvals = MakeQuadPoints(bigknots,nquad);   

% Now we can create the basis and Lfd objects to popluate 'basis_cell'
% and 'Lfd_cell'. In this case 'MakeBasis' simply creates a B-spline basis
% and attaches 'quadvals' as quadrature points. We have chosen 'Lfd_cell'
% to contain objects penalizing the first derivative of a smooth.    

for i = 1:length(Ycell)
    basis_cell{i} = MakeBasis(range,nbasis(i),norder,...  
        knots_cell{i},quadvals,1);                        
    Lfd_cell{i} = fdPar(basis_cell{i},1,lambda0);         
end

%% Smooth the data

% As a first step, we create a smooth of the data without reference to the
% differential equation. 'smoothfd_cell' does this for each component
% individually using the penalty specified in 'Lfd_cell'. 

DEfd = smoothfd_cell(Ycell,Tcell,Lfd_cell);

% We will use the coefficients estimated via this smooth as initial values
% for the non-linear smoothing problem when we use a model-based penalty.
% getcellcoefs takes a cell array of functional data objects and
% returns a vector concatenating all the coefficient vectors. 

coefs = getcellcoefs(DEfd);

% plot the smooth

figure(2)
devals = eval_fdcell(tfine,DEfd,0);
for i = 1:length(Ycell)
    subplot(length(Ycell),1,i);
    plot(tfine,devals{i},'r','LineWidth',2);
    hold on;
    plot(Tcell{i},Ycell{i},'b.');
    hold off;
    if i==1
        ylabel('\fontsize{13} V')
        title('\fontsize{13} Raw data (.) and smoothing path (-)')
    else
        xlabel('\fontsize{13} t')
        ylabel('\fontsize{13} R')
    end
end


%% Re-smoothing with model-based penalty
%
% Now we get into some of the grunt work of the method. First, we will
% smooth the data using the differential equation as a penalty, but with
% the jittered parameters. 

% This is done by a call to the MATLAB optimizer 'lsqnonlin' which
% gives out the optimized coefficients of the basis. 

[newcoefs,resnorm2] = lsqnonlin(@SplineCoefErr,coefs,[],[],...
    lsopts_other,basis_cell,Ycell,Tcell,wts,lambda,fn,[],startpars);

% 'Make_fdcell' takes those coefficients and creates functional data
% objects using the entries in 'basis_cell'. 

tDEfd = Make_fdcell(newcoefs,basis_cell);

% plot results along with exact solution

figure(3)
devals = eval_fdcell(tfine,tDEfd,0);
for i = 1:length(Ycell)
    subplot(length(Ycell),1,i);
    plot(tfine,devals{i},'r','LineWidth',2);
    hold on;
    plot(Tcell{i},Ycell{i},'b.');
    plot(plot_time,plot_path(:,i),'g');
    hold off
    if i==1
        ylabel('\fontsize{13} V')
        title(['\fontsize{13} Raw data (.), ', ...
               'exact solution (r-) and true path (g-)'])
    else
        xlabel('\fontsize{13} t')
        ylabel('\fontsize{13} R')
    end
end



%% Perform the Profiled Estimation
%
% |Profile_GausNewt| runs the Guass-Newton iteration for the outer
% optimization in profiling. It outputs the new parameter estimates along
% with a cell-array of functional data objects that give the model-based
% smooth to the data 

[newpars,newDEfd_cell] = Profile_GausNewt(startpars,lsopts_out,DEfd,fn,...
    lambda,Ycell,Tcell,wts,[],lsopts_in);

disp(['New parameter estimates: ',num2str(newpars')]);

% plot smooth with profile-estimated parameters

figure(4)
devals = eval_fdcell(tfine,newDEfd_cell,0);
for i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(tfine,devals{i},'r','LineWidth',2);
    hold on;
    plot(Tcell{i},Ycell{i},'b.');
    plot(plot_time,plot_path(:,i),'g','linewidth',2);
    hold off
    if i==1
        ylabel('\fontsize{13} V')
        title(['\fontsize{13} Raw data (.), ', ...
               'profiled solution (r-) and true path (g-)'])
    else
        xlabel('\fontsize{13} t')
        ylabel('\fontsize{13} R')
    end
end


%% Comparison with Smooth Using True Parameters
%
% How different is the smooth resulting from the estimated parameter values
% as compared with the true parameter values? Here we smooth again, but
% using the true parameter values.

% We'll start off with the estimated coefficients.

coefs = getcellcoefs(DEfd);

% and make a call to 'lsqnonlin'.

[truecoefs,resnorm4] = lsqnonlin(@SplineCoefErr,coefs,[],[],...
    lsopts_other,basis_cell,Ycell,Tcell,wts,lambda,fn,[],pars);

% then create the functional data objects and plot them

trueDEfd_cell = Make_fdcell(truecoefs,basis_cell);

figure(5)
devals = eval_fdcell(tfine,trueDEfd_cell,0);
for i = 1:length(Ycell)
    subplot(length(Ycell),1,i)
    plot(tfine,devals{i},'r','LineWidth',2);
    hold on;
    plot(plot_time,plot_path(:,i),'g');
    plot(Tcell{i},Ycell{i},'b.');
    hold off;
    if i==1
        ylabel('\fontsize{13} V')
        title(['\fontsize{13} Raw data (.), ', ...
               'true par. smooth (r-) and true path (g-)'])
    else
        xlabel('\fontsize{13} t')
        ylabel('\fontsize{13} R')
    end
end

% Finally we will compare squared error performance. To do this, we will
% first of all need to evaluate the functional data objects at the
% observatio points. 'eval_fdcell' does this:

newpreds = eval_fdcell(Tcell,newDEfd_cell,0);

% then we can create the weighted squared error pointwise

new_err = cell(length(newpreds));
for i = 1:length(Ycell)
    new_err{i} = wts(i)*(newpreds{i} - Ycell{i}).^2;
end

% 'cell2mat' is a handy function that will turn a cell array of matrices,
% into a large matrix using the elements of the cells as blocks. We can
% then take the mean accross all values. 

new_err = mean(cell2mat(new_err));

% Now we can do the same thing for the smooth using the true parameters

truepreds = eval_fdcell(Tcell,trueDEfd_cell,0);
true_err = cell(length(truepreds));
for i = 1:length(Ycell)
    true_err{i} = wts(i)*(truepreds{i} - Ycell{i}).^2;
end

true_err = mean(cell2mat(true_err));

% and print out a comparison of the squared errors

disp(['Estimated sqrd error: ',num2str(new_err)])
disp(['True sqrd error:      ',num2str(true_err)]);


%% Calculate Sample Information and Variance-Covariance Matrices
%
% Finally, we want to get an idea of the variability of the parameter
% estimates. 

% We will start with the Hessian of squared error with respect to the
% parameters: 

d2Jdp2 = make_d2jdp2(newDEfd_cell,fn,Ycell,Tcell,lambda,newpars,[],wts);

% We then want the cross derivatives of squared error with respect to
% parameters and observations:

d2JdpdY = make_d2jdpdy(newDEfd_cell,fn,Ycell,Tcell,lambda,newpars,[],wts);

% This allows us to calculate the derivative of the parameters with respect
% to observations:

dpdY = -d2Jdp2\d2JdpdY;

% Now we need to estimate how variable those observations are:

S = make_sigma(DEfd,Tcell,Ycell,0);

% And this gives an approximate covariance matrix for the parameters:

Cov = dpdY*S*dpdY';

%  Standard errors

StdDev = sqrt(diag(Cov));

%  Correlations

Corr = Cov./(StdDev*StdDev');

%  Display these results

disp('Approximate covariance matrix for parameters:')
disp(num2str(Cov))

disp('Approximate standard errors of parameters:')
disp(num2str(StdDev'))

disp('Approximate correlation matrix for parameters:')
disp(num2str(Corr))





##### SOURCE END #####
-->
   </body>
</html>